{"title":"Ollama Modelfile 规则说明","date":"2025-02-20T00:41:47.783Z","slug":"Ollama Modelfile 规则说明","comments":true,"tags":["Modelfile","Ollama","人工智能","大模型","模型训练","模型转换"],"updated":"2025-02-20T00:45:20.376Z","content":"<h2 id=\"简介\">简介<a href=\"post/Ollama Modelfile 规则说明#简介\"></a></h2><p><code>Modelfile</code> 是用于定义 Ollama 模型的配置文件，它允许用户指定基础模型、参数、模型文件路径等信息。</p>\n<h2 id=\"语法\">语法<a href=\"post/Ollama Modelfile 规则说明#语法\"></a></h2><p><code>Modelfile</code> 采用简单的 <code>key value</code> 格式，每行一个指令。</p>\n<h3 id=\"示例\">示例<a href=\"post/Ollama Modelfile 规则说明#示例\"></a></h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM deepseek-ai/deepseek-llm-1.5b</span><br><span class=\"line\">PARAMETER temperature=0.7</span><br><span class=\"line\">PARAMETER top_p=0.9</span><br><span class=\"line\">SYSTEM &quot;你是一个帮助用户回答问题的 AI。&quot;</span><br><span class=\"line\">FILE tokenizer.json /app/tokenizer.json</span><br></pre></td></tr></table></figure>\n<h2 id=\"关键指令\">关键指令<a href=\"post/Ollama Modelfile 规则说明#关键指令\"></a></h2><h3 id=\"1-FROM\">1. FROM<a href=\"post/Ollama Modelfile 规则说明#1-FROM\"></a></h3><p>指定模型的基础模型。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM deepseek-ai/deepseek-llm-1.5b</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"2-PARAMETER\">2. PARAMETER<a href=\"post/Ollama Modelfile 规则说明#2-PARAMETER\"></a></h3><p>设定推理参数，例如温度（<code>temperature</code>）和概率截断（<code>top_p</code>）。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PARAMETER temperature=0.7</span><br><span class=\"line\">PARAMETER top_p=0.9</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"3-SYSTEM\">3. SYSTEM<a href=\"post/Ollama Modelfile 规则说明#3-SYSTEM\"></a></h3><p>设定系统提示词，影响模型的行为。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SYSTEM &quot;你是一个帮助用户回答问题的 AI。&quot;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"4-FILE\">4. FILE<a href=\"post/Ollama Modelfile 规则说明#4-FILE\"></a></h3><p>指定额外文件，例如 tokenizer 配置文件。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FILE tokenizer.json /app/tokenizer.json</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"其他指令\">其他指令<a href=\"post/Ollama Modelfile 规则说明#其他指令\"></a></h2><p>未来可能支持更多指令，建议参考官方文档进行扩展。</p>\n<h2 id=\"结论\">结论<a href=\"post/Ollama Modelfile 规则说明#结论\"></a></h2><p><code>Modelfile</code> 允许用户方便地自定义 Ollama 模型的行为和配置，使得本地运行和部署变得更加灵活。</p>\n","prev":{"title":"如何将 Hugging Face 模型转换并加载到 Ollama（Windows 版）","slug":"如何将HuggingFace模型转换并加载到Ollama_Windows版"},"next":{"title":"Windows 安装 CUDA 详细步骤","slug":"Windows 安装 CUDA 详细步骤"},"link":"https://www.alipay.one/post/Ollama Modelfile 规则说明/","toc":[{"title":"简介","id":"简介","index":"1"},{"title":"语法","id":"语法","index":"2","children":[{"title":"示例","id":"示例","index":"2.1"}]},{"title":"关键指令","id":"关键指令","index":"3","children":[{"title":"1. FROM","id":"1-FROM","index":"3.1"},{"title":"2. PARAMETER","id":"2-PARAMETER","index":"3.2"},{"title":"3. SYSTEM","id":"3-SYSTEM","index":"3.3"},{"title":"4. FILE","id":"4-FILE","index":"3.4"}]},{"title":"其他指令","id":"其他指令","index":"4"},{"title":"结论","id":"结论","index":"5"}]}